{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "59672e40",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-18T10:14:53.016888Z",
     "iopub.status.busy": "2025-11-18T10:14:53.016103Z",
     "iopub.status.idle": "2025-11-18T10:15:02.644033Z",
     "shell.execute_reply": "2025-11-18T10:15:02.642833Z"
    },
    "papermill": {
     "duration": 9.636479,
     "end_time": "2025-11-18T10:15:02.646017",
     "exception": false,
     "start_time": "2025-11-18T10:14:53.009538",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers in /usr/local/lib/python3.11/dist-packages (4.53.3)\r\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from transformers) (3.20.0)\r\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.30.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.36.0)\r\n",
      "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (1.26.4)\r\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (25.0)\r\n",
      "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from transformers) (6.0.3)\r\n",
      "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2025.11.3)\r\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from transformers) (2.32.5)\r\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.21.2)\r\n",
      "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.5.3)\r\n",
      "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.11/dist-packages (from transformers) (4.67.1)\r\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.30.0->transformers) (2025.10.0)\r\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.30.0->transformers) (4.15.0)\r\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.30.0->transformers) (1.2.0)\r\n",
      "Requirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->transformers) (1.3.8)\r\n",
      "Requirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->transformers) (1.2.4)\r\n",
      "Requirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->transformers) (0.1.1)\r\n",
      "Requirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->transformers) (2025.3.0)\r\n",
      "Requirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->transformers) (2022.3.0)\r\n",
      "Requirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->transformers) (2.4.1)\r\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.4.4)\r\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.11)\r\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2.5.0)\r\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2025.10.5)\r\n",
      "Requirement already satisfied: onemkl-license==2025.3.0 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.17->transformers) (2025.3.0)\r\n",
      "Requirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.17->transformers) (2024.2.0)\r\n",
      "Requirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.17->transformers) (2022.3.0)\r\n",
      "Requirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy>=1.17->transformers) (1.4.0)\r\n",
      "Requirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy>=1.17->transformers) (2024.2.0)\r\n",
      "Requirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy>=1.17->transformers) (2024.2.0)\r\n",
      "Collecting protobuf==3.20.3\r\n",
      "  Downloading protobuf-3.20.3-py2.py3-none-any.whl.metadata (720 bytes)\r\n",
      "Downloading protobuf-3.20.3-py2.py3-none-any.whl (162 kB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m162.1/162.1 kB\u001b[0m \u001b[31m8.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hInstalling collected packages: protobuf\r\n",
      "  Attempting uninstall: protobuf\r\n",
      "    Found existing installation: protobuf 6.33.0\r\n",
      "    Uninstalling protobuf-6.33.0:\r\n",
      "      Successfully uninstalled protobuf-6.33.0\r\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\r\n",
      "bigframes 2.12.0 requires google-cloud-bigquery-storage<3.0.0,>=2.30.0, which is not installed.\r\n",
      "opentelemetry-proto 1.37.0 requires protobuf<7.0,>=5.0, but you have protobuf 3.20.3 which is incompatible.\r\n",
      "onnx 1.18.0 requires protobuf>=4.25.1, but you have protobuf 3.20.3 which is incompatible.\r\n",
      "a2a-sdk 0.3.10 requires protobuf>=5.29.5, but you have protobuf 3.20.3 which is incompatible.\r\n",
      "ray 2.51.1 requires click!=8.3.0,>=7.0, but you have click 8.3.0 which is incompatible.\r\n",
      "bigframes 2.12.0 requires rich<14,>=12.4.4, but you have rich 14.2.0 which is incompatible.\r\n",
      "tensorflow-metadata 1.17.2 requires protobuf>=4.25.2; python_version >= \"3.11\", but you have protobuf 3.20.3 which is incompatible.\r\n",
      "pydrive2 1.21.3 requires cryptography<44, but you have cryptography 46.0.3 which is incompatible.\r\n",
      "pydrive2 1.21.3 requires pyOpenSSL<=24.2.1,>=19.1.0, but you have pyopenssl 25.3.0 which is incompatible.\r\n",
      "ydf 0.13.0 requires protobuf<7.0.0,>=5.29.1, but you have protobuf 3.20.3 which is incompatible.\r\n",
      "grpcio-status 1.71.2 requires protobuf<6.0dev,>=5.26.1, but you have protobuf 3.20.3 which is incompatible.\r\n",
      "gcsfs 2025.3.0 requires fsspec==2025.3.0, but you have fsspec 2025.10.0 which is incompatible.\u001b[0m\u001b[31m\r\n",
      "\u001b[0mSuccessfully installed protobuf-3.20.3\r\n"
     ]
    }
   ],
   "source": [
    "!pip install transformers \n",
    "!pip install protobuf==3.20.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5980bec8",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2025-11-18T10:15:02.657398Z",
     "iopub.status.busy": "2025-11-18T10:15:02.657010Z",
     "iopub.status.idle": "2025-11-18T10:15:19.462897Z",
     "shell.execute_reply": "2025-11-18T10:15:19.462012Z"
    },
    "papermill": {
     "duration": 16.813446,
     "end_time": "2025-11-18T10:15:19.464704",
     "exception": false,
     "start_time": "2025-11-18T10:15:02.651258",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/pydantic/_internal/_generate_schema.py:2249: UnsupportedFieldAttributeWarning: The 'repr' attribute with value False was provided to the `Field()` function, which has no effect in the context it was used. 'repr' is field-specific metadata, and can only be attached to a model field using `Annotated` metadata or by assignment. This may have happened because an `Annotated` type alias using the `type` statement was used, or if the `Field()` function was attached to a single member of a union type.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.11/dist-packages/pydantic/_internal/_generate_schema.py:2249: UnsupportedFieldAttributeWarning: The 'frozen' attribute with value True was provided to the `Field()` function, which has no effect in the context it was used. 'frozen' is field-specific metadata, and can only be attached to a model field using `Annotated` metadata or by assignment. This may have happened because an `Annotated` type alias using the `type` statement was used, or if the `Field()` function was attached to a single member of a union type.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd \n",
    "import numpy as np \n",
    "import os \n",
    "import glob \n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.nn as nn\n",
    "from torch.optim import AdamW\n",
    "from torch.optim.lr_scheduler import CosineAnnealingLR\n",
    "import timm # For pre-trained models\n",
    "from tqdm import tqdm # For progress bars\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26cc4b4b",
   "metadata": {
    "papermill": {
     "duration": 0.004422,
     "end_time": "2025-11-18T10:15:19.473952",
     "exception": false,
     "start_time": "2025-11-18T10:15:19.469530",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a81b9b8b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-18T10:15:19.484338Z",
     "iopub.status.busy": "2025-11-18T10:15:19.483961Z",
     "iopub.status.idle": "2025-11-18T10:15:44.837253Z",
     "shell.execute_reply": "2025-11-18T10:15:44.836147Z"
    },
    "papermill": {
     "duration": 25.360514,
     "end_time": "2025-11-18T10:15:44.838896",
     "exception": false,
     "start_time": "2025-11-18T10:15:19.478382",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-18 10:15:23.123789: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1763460923.320252      13 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1763460923.379337      13 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "Using a slow image processor as `use_fast` is unset and a slow processor was saved with this model. `use_fast=True` will be the default behavior in v4.52, even if the model was saved with a slow processor. This will result in minor differences in outputs. You'll still be able to use a slow processor with `use_fast=False`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DINOv2 model loaded successfully from local files.\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import AutoImageProcessor, AutoModel\n",
    "\n",
    "# This is the path to the dataset you added in Step 1\n",
    "# The exact path may vary slightly based on which dataset you chose.\n",
    "MODEL_PATH = '/kaggle/input/dinov2/pytorch/small/1' \n",
    "\n",
    "# Load the processor from the local files\n",
    "processor = AutoImageProcessor.from_pretrained(MODEL_PATH)\n",
    "\n",
    "# Load the model from the local files\n",
    "model = AutoModel.from_pretrained(MODEL_PATH)\n",
    "\n",
    "model.eval()\n",
    "print(\"DINOv2 model loaded successfully from local files.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "117ac3ff",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-18T10:15:44.850730Z",
     "iopub.status.busy": "2025-11-18T10:15:44.849913Z",
     "iopub.status.idle": "2025-11-18T10:15:44.856223Z",
     "shell.execute_reply": "2025-11-18T10:15:44.855091Z"
    },
    "papermill": {
     "duration": 0.013898,
     "end_time": "2025-11-18T10:15:44.857631",
     "exception": false,
     "start_time": "2025-11-18T10:15:44.843733",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cpu\n"
     ]
    }
   ],
   "source": [
    "# --- Setup ---\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "36221935",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-18T10:15:44.868455Z",
     "iopub.status.busy": "2025-11-18T10:15:44.868071Z",
     "iopub.status.idle": "2025-11-18T10:15:44.889926Z",
     "shell.execute_reply": "2025-11-18T10:15:44.889022Z"
    },
    "papermill": {
     "duration": 0.029225,
     "end_time": "2025-11-18T10:15:44.891596",
     "exception": false,
     "start_time": "2025-11-18T10:15:44.862371",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "BASE_PATH='/kaggle/input/csiro-biomass'\n",
    "train_meta=pd.read_csv(os.path.join(BASE_PATH,'train.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fb4138f4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-18T10:15:44.903000Z",
     "iopub.status.busy": "2025-11-18T10:15:44.902665Z",
     "iopub.status.idle": "2025-11-18T10:15:44.935144Z",
     "shell.execute_reply": "2025-11-18T10:15:44.934129Z"
    },
    "papermill": {
     "duration": 0.04027,
     "end_time": "2025-11-18T10:15:44.937010",
     "exception": false,
     "start_time": "2025-11-18T10:15:44.896740",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 1. Pivot the target variables\n",
    "# (Pivoting on 'image_id' is a bit cleaner than the full path)\n",
    "targets_df = train_meta.pivot(index='image_path', \n",
    "                              columns='target_name', \n",
    "                              values='target')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "85ece8a5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-18T10:15:44.948260Z",
     "iopub.status.busy": "2025-11-18T10:15:44.947923Z",
     "iopub.status.idle": "2025-11-18T10:15:44.957726Z",
     "shell.execute_reply": "2025-11-18T10:15:44.956816Z"
    },
    "papermill": {
     "duration": 0.0171,
     "end_time": "2025-11-18T10:15:44.959124",
     "exception": false,
     "start_time": "2025-11-18T10:15:44.942024",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 2. Get the unique metadata for each image\n",
    "# (State, Species, etc. are repeated, so we just grab the first instance)\n",
    "meta_df = train_meta[[  'image_path', 'Sampling_Date', 'State', 'Species',\n",
    "       'Pre_GSHH_NDVI', 'Height_Ave_cm']] \\\n",
    "                      .drop_duplicates(subset='image_path') \\\n",
    "                      .set_index('image_path')\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8d5f0743",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-18T10:15:44.970793Z",
     "iopub.status.busy": "2025-11-18T10:15:44.970061Z",
     "iopub.status.idle": "2025-11-18T10:15:44.978738Z",
     "shell.execute_reply": "2025-11-18T10:15:44.978015Z"
    },
    "papermill": {
     "duration": 0.015576,
     "end_time": "2025-11-18T10:15:44.979937",
     "exception": false,
     "start_time": "2025-11-18T10:15:44.964361",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 3. Join them together\n",
    "# This creates one clean row per image with all data\n",
    "train_df = meta_df.join(targets_df).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "962701d3",
   "metadata": {
    "papermill": {
     "duration": 0.004462,
     "end_time": "2025-11-18T10:15:44.989335",
     "exception": false,
     "start_time": "2025-11-18T10:15:44.984873",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4ed77934",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-18T10:15:44.999657Z",
     "iopub.status.busy": "2025-11-18T10:15:44.999326Z",
     "iopub.status.idle": "2025-11-18T10:15:45.014343Z",
     "shell.execute_reply": "2025-11-18T10:15:45.013316Z"
    },
    "papermill": {
     "duration": 0.021993,
     "end_time": "2025-11-18T10:15:45.015760",
     "exception": false,
     "start_time": "2025-11-18T10:15:44.993767",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               image_path Sampling_Date State            Species  \\\n",
      "0  train/ID1011485656.jpg      2015/9/4   Tas    Ryegrass_Clover   \n",
      "1  train/ID1012260530.jpg      2015/4/1   NSW            Lucerne   \n",
      "2  train/ID1025234388.jpg      2015/9/1    WA  SubcloverDalkeith   \n",
      "3  train/ID1028611175.jpg     2015/5/18   Tas           Ryegrass   \n",
      "4  train/ID1035947949.jpg     2015/9/11   Tas           Ryegrass   \n",
      "\n",
      "   Pre_GSHH_NDVI  Height_Ave_cm  Dry_Clover_g  Dry_Dead_g  Dry_Green_g  \\\n",
      "0           0.62         4.6667        0.0000     31.9984      16.2751   \n",
      "1           0.55        16.0000        0.0000      0.0000       7.6000   \n",
      "2           0.38         1.0000        6.0500      0.0000       0.0000   \n",
      "3           0.66         5.0000        0.0000     30.9703      24.2376   \n",
      "4           0.54         3.5000        0.4343     23.2239      10.5261   \n",
      "\n",
      "   Dry_Total_g    GDM_g  \n",
      "0      48.2735  16.2750  \n",
      "1       7.6000   7.6000  \n",
      "2       6.0500   6.0500  \n",
      "3      55.2079  24.2376  \n",
      "4      34.1844  10.9605  \n"
     ]
    }
   ],
   "source": [
    "# 4. Define our 5 output targets\n",
    "TARGET_COLS = list(train_df.columns[-5:])\n",
    "\n",
    "\n",
    "# Weights: [Dry_Total_g, Dry_Green_g, Dry_Dead_g, Dry_Clover_g, Dry_Grass_g]\n",
    "COMP_WEIGHTS = torch.tensor([0.5, 0.2, 0.1, 0.1,0.1]).to(device)\n",
    "\n",
    "# Now train_df is ready!\n",
    "print(train_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "087f4fdc",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-18T10:15:45.028071Z",
     "iopub.status.busy": "2025-11-18T10:15:45.027111Z",
     "iopub.status.idle": "2025-11-18T10:15:45.032263Z",
     "shell.execute_reply": "2025-11-18T10:15:45.031468Z"
    },
    "papermill": {
     "duration": 0.012619,
     "end_time": "2025-11-18T10:15:45.033605",
     "exception": false,
     "start_time": "2025-11-18T10:15:45.020986",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_df_sample = train_df.iloc[:round(len(train_df)*0.8)]\n",
    "val_df_sample = train_df.iloc[round(len(train_df)*0.8):]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "008dc148",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-18T10:15:45.045296Z",
     "iopub.status.busy": "2025-11-18T10:15:45.044465Z",
     "iopub.status.idle": "2025-11-18T10:15:45.051613Z",
     "shell.execute_reply": "2025-11-18T10:15:45.050526Z"
    },
    "papermill": {
     "duration": 0.014342,
     "end_time": "2025-11-18T10:15:45.053064",
     "exception": false,
     "start_time": "2025-11-18T10:15:45.038722",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(71, 11)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_df_sample.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "40611e52",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-18T10:15:45.065405Z",
     "iopub.status.busy": "2025-11-18T10:15:45.064967Z",
     "iopub.status.idle": "2025-11-18T10:15:45.633932Z",
     "shell.execute_reply": "2025-11-18T10:15:45.633039Z"
    },
    "papermill": {
     "duration": 0.576651,
     "end_time": "2025-11-18T10:15:45.635474",
     "exception": false,
     "start_time": "2025-11-18T10:15:45.058823",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_13/2830425699.py:17: UserWarning: Argument(s) 'max_holes, max_height, max_width' are not valid for transform CoarseDropout\n",
      "  A.CoarseDropout(max_holes=8, max_height=32, max_width=32, p=0.5),\n"
     ]
    }
   ],
   "source": [
    "# First, you might need to install it:\n",
    "\n",
    "import albumentations as A\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "import cv2 # Albumentations uses OpenCV\n",
    "\n",
    "# --- 1. Define your transforms ---\n",
    "# These are applied ONLY to the training data\n",
    "train_transforms = A.Compose([\n",
    "    A.Resize(256, 256),            # Resize all images to 256x256\n",
    "    A.HorizontalFlip(p=0.5),     # 50% chance to flip horizontally\n",
    "    A.VerticalFlip(p=0.5),       # 50% chance to flip vertically\n",
    "    A.RandomRotate90(p=0.5),     # 50% chance to rotate 90 degrees\n",
    "    \n",
    "    # Color/Distortion\n",
    "    A.GaussNoise(p=0.2),\n",
    "    A.CoarseDropout(max_holes=8, max_height=32, max_width=32, p=0.5),\n",
    "    \n",
    "    # Normalize (use mean/std of ImageNet)\n",
    "    A.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "    \n",
    "    # Convert to PyTorch Tensor\n",
    "    ToTensorV2()\n",
    "])\n",
    "\n",
    "# These are for validation. We ONLY resize and normalize. No flipping/distortion.\n",
    "val_transforms = A.Compose([\n",
    "    A.Resize(256, 256),\n",
    "    A.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "    ToTensorV2()\n",
    "])\n",
    "\n",
    "\n",
    "# --- 2. Update the Custom Dataset Class ---\n",
    "class BiomassDataset(Dataset):\n",
    "    def __init__(self, df, target_cols, base_path, processor,model,transforms=None,):\n",
    "        self.df = df\n",
    "        self.image_paths = [os.path.join(base_path, p) for p in df['image_path']]\n",
    "        self.labels = df[target_cols].values.astype(np.float32)\n",
    "        self.transforms = transforms # <-- NEW\n",
    "        \n",
    "        self.model=model\n",
    "        self.processor=processor \n",
    "    def __len__(self):\n",
    "        return len(self.image_paths)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        image_path = self.image_paths[idx]\n",
    "        feature_list=[]\n",
    "        # Load image with OpenCV (used by albumentations)\n",
    "        # cv2 loads as BGR, so we convert to RGB\n",
    "        image = cv2.imread(image_path)\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "        \n",
    "        labels = self.labels[idx]\n",
    "\n",
    "        image_features=self.processor(image,return_tensors='pt')\n",
    "\n",
    "        with torch.no_grad():\n",
    "            model_out=self.model(**image_features)\n",
    "            feature_list.append(model_out.pooler_output.cpu())\n",
    "        \n",
    "        # Apply transforms (if they exist)\n",
    "        if self.transforms:\n",
    "            # Albumentations returns a dictionary\n",
    "            transformed = self.transforms(image=image)\n",
    "            image = transformed['image']\n",
    "        \n",
    "        # Labels are already a numpy array, just convert to tensor\n",
    "        labels = torch.tensor(labels)\n",
    "\n",
    "        return image, labels,np.array(feature_list)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "94ebc394",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-18T10:15:45.647426Z",
     "iopub.status.busy": "2025-11-18T10:15:45.646685Z",
     "iopub.status.idle": "2025-11-18T10:15:45.654768Z",
     "shell.execute_reply": "2025-11-18T10:15:45.653946Z"
    },
    "papermill": {
     "duration": 0.01543,
     "end_time": "2025-11-18T10:15:45.656195",
     "exception": false,
     "start_time": "2025-11-18T10:15:45.640765",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "# --- 3. Create Datasets with new transforms ---\n",
    "train_dataset = BiomassDataset(df=train_df_sample, \n",
    "                               target_cols=TARGET_COLS, \n",
    "                               base_path=BASE_PATH,\n",
    "                               transforms=None,processor=processor,model=model) # <-- Pass transforms\n",
    "\n",
    "val_dataset = BiomassDataset(df=val_df_sample, \n",
    "                             target_cols=TARGET_COLS, \n",
    "                             base_path=BASE_PATH,\n",
    "                             transforms=None,processor=processor,model=model) # <-- Pass transforms\n",
    "\n",
    "# DataLoaders are created the same way\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True, num_workers=2)\n",
    "val_loader = DataLoader(val_dataset, batch_size=64, shuffle=False, num_workers=2)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "039fab72",
   "metadata": {
    "papermill": {
     "duration": 0.004873,
     "end_time": "2025-11-18T10:15:45.666193",
     "exception": false,
     "start_time": "2025-11-18T10:15:45.661320",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "046f1bae",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-18T10:15:45.677232Z",
     "iopub.status.busy": "2025-11-18T10:15:45.676902Z",
     "iopub.status.idle": "2025-11-18T10:16:07.581874Z",
     "shell.execute_reply": "2025-11-18T10:16:07.580601Z"
    },
    "papermill": {
     "duration": 21.912573,
     "end_time": "2025-11-18T10:16:07.583604",
     "exception": false,
     "start_time": "2025-11-18T10:15:45.671031",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image batch shape: torch.Size([32, 1000, 2000, 3])\n",
      "Labels batch shape: torch.Size([32, 5])\n",
      "Feature batch shape: torch.Size([32, 1, 1, 384])\n"
     ]
    }
   ],
   "source": [
    "# Test it\n",
    "images, labels,encodings = next(iter(train_loader))\n",
    "\n",
    "print(f\"Image batch shape: {images.shape}\") # Should be [32, 3, 256, 256]\n",
    "print(f\"Labels batch shape: {labels.shape}\") # Should be [32, 5]\n",
    "print(f\"Feature batch shape: {encodings.shape}\")\n",
    "# Image batch shape: torch.Size([32, 1000, 2000, 3])\n",
    "# Labels batch shape: torch.Size([32, 5])\n",
    "# Feature batch shape: torch.Size([32, 1, 1, 384])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8afd73f6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-18T10:16:07.596918Z",
     "iopub.status.busy": "2025-11-18T10:16:07.596252Z",
     "iopub.status.idle": "2025-11-18T10:17:03.093506Z",
     "shell.execute_reply": "2025-11-18T10:17:03.092337Z"
    },
    "papermill": {
     "duration": 55.505821,
     "end_time": "2025-11-18T10:17:03.095142",
     "exception": false,
     "start_time": "2025-11-18T10:16:07.589321",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting features from existing pipeline...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9/9 [00:55<00:00,  6.16s/it]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Containers for the full dataset\n",
    "all_features = []\n",
    "all_labels = []\n",
    "\n",
    "print(\"Extracting features from existing pipeline...\")\n",
    "\n",
    "for images, labels, encodings in tqdm(train_loader):\n",
    "    \n",
    " \n",
    "    # .view(batch_size, -1) flattens everything after the batch dimension\n",
    "    batch_features = encodings.view(encodings.shape[0], -1).cpu().numpy()\n",
    "    \n",
    "    # 2. Convert labels to numpy\n",
    "    batch_labels = labels.cpu().numpy()\n",
    "    \n",
    "    # 3. Collect\n",
    "    all_features.append(batch_features)\n",
    "    all_labels.append(batch_labels)\n",
    "\n",
    "# Concatenate all batches into single numpy arrays\n",
    "X_train = np.vstack(all_features)\n",
    "y_train = np.vstack(all_labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "46844619",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-18T10:17:03.108755Z",
     "iopub.status.busy": "2025-11-18T10:17:03.108110Z",
     "iopub.status.idle": "2025-11-18T10:17:26.483226Z",
     "shell.execute_reply": "2025-11-18T10:17:26.482078Z"
    },
    "papermill": {
     "duration": 23.383309,
     "end_time": "2025-11-18T10:17:26.484673",
     "exception": false,
     "start_time": "2025-11-18T10:17:03.101364",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [00:23<00:00, 11.68s/it]\n"
     ]
    }
   ],
   "source": [
    "# Containers for the full dataset\n",
    "all_features_val = []\n",
    "all_labels_val = []\n",
    "for images, labels, encodings in tqdm(val_loader):\n",
    "    \n",
    " \n",
    "    # .view(batch_size, -1) flattens everything after the batch dimension\n",
    "    batch_features_val = encodings.view(encodings.shape[0], -1).cpu().numpy()\n",
    "    \n",
    "    # 2. Convert labels to numpy\n",
    "    batch_labels_val = labels.cpu().numpy()\n",
    "    \n",
    "    # 3. Collect\n",
    "    all_features_val.append(batch_features_val)\n",
    "    all_labels_val.append(batch_labels_val)\n",
    "\n",
    "# Concatenate all batches into single numpy arrays\n",
    "X_val = np.vstack(all_features_val)\n",
    "y_val = np.vstack(all_labels_val)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9c07ffca",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-18T10:17:26.498675Z",
     "iopub.status.busy": "2025-11-18T10:17:26.497948Z",
     "iopub.status.idle": "2025-11-18T10:17:26.503052Z",
     "shell.execute_reply": "2025-11-18T10:17:26.502405Z"
    },
    "papermill": {
     "duration": 0.013419,
     "end_time": "2025-11-18T10:17:26.504338",
     "exception": false,
     "start_time": "2025-11-18T10:17:26.490919",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final Feature Matrix X: (71, 384)\n",
      "Final Label Matrix y:   (71, 5)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(f\"Final Feature Matrix X: {X_val.shape}\") # Should be (Total_Images, 384)\n",
    "print(f\"Final Label Matrix y:   {y_val.shape}\") # Should be (Total_Images, 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d8bb417",
   "metadata": {
    "papermill": {
     "duration": 0.005808,
     "end_time": "2025-11-18T10:17:26.516023",
     "exception": false,
     "start_time": "2025-11-18T10:17:26.510215",
     "status": "completed"
    },
    "tags": []
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "11e7998e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-18T10:17:26.528913Z",
     "iopub.status.busy": "2025-11-18T10:17:26.528613Z",
     "iopub.status.idle": "2025-11-18T10:17:26.533477Z",
     "shell.execute_reply": "2025-11-18T10:17:26.532568Z"
    },
    "papermill": {
     "duration": 0.012978,
     "end_time": "2025-11-18T10:17:26.534764",
     "exception": false,
     "start_time": "2025-11-18T10:17:26.521786",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final Feature Matrix X: (286, 384)\n",
      "Final Label Matrix y:   (286, 5)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(f\"Final Feature Matrix X: {X_train.shape}\") # Should be (Total_Images, 384)\n",
    "print(f\"Final Label Matrix y:   {y_train.shape}\") # Should be (Total_Images, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4f7e6229",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-18T10:17:26.548117Z",
     "iopub.status.busy": "2025-11-18T10:17:26.547476Z",
     "iopub.status.idle": "2025-11-18T10:19:23.923206Z",
     "shell.execute_reply": "2025-11-18T10:19:23.921263Z"
    },
    "papermill": {
     "duration": 117.384185,
     "end_time": "2025-11-18T10:19:23.924851",
     "exception": false,
     "start_time": "2025-11-18T10:17:26.540666",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training XGBoost...\n",
      "Training LightGBM...\n",
      "Calculating Ensemble Predictions...\n",
      "Ensemble Validation MAE: 8.6996\n"
     ]
    }
   ],
   "source": [
    "import xgboost as xgb\n",
    "import lightgbm as lgb\n",
    "from sklearn.multioutput import MultiOutputRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "\n",
    "\n",
    "# --- MODEL 1: XGBoost ---\n",
    "print(\"Training XGBoost...\")\n",
    "# Note: 'tree_method': 'hist' makes it much faster\n",
    "xgb_est = xgb.XGBRegressor(n_estimators=1000, learning_rate=0.05, max_depth=6, tree_method='hist', n_jobs=-1)\n",
    "model_xgb = MultiOutputRegressor(xgb_est)\n",
    "model_xgb.fit(X_train, y_train)\n",
    "\n",
    "# --- MODEL 2: LightGBM ---\n",
    "print(\"Training LightGBM...\")\n",
    "lgb_est = lgb.LGBMRegressor(n_estimators=1000, learning_rate=0.05, num_leaves=31, n_jobs=-1, verbose=-1)\n",
    "model_lgb = MultiOutputRegressor(lgb_est)\n",
    "model_lgb.fit(X_train, y_train)\n",
    "\n",
    "# --- PREDICT & ENSEMBLE ---\n",
    "print(\"Calculating Ensemble Predictions...\")\n",
    "preds_xgb = model_xgb.predict(X_val)\n",
    "preds_lgb = model_lgb.predict(X_val)\n",
    "\n",
    "# Average the predictions (50% XGB + 50% LGBM)\n",
    "ensemble_preds = (0.5 * preds_xgb) + (0.5 * preds_lgb)\n",
    "\n",
    "# --- POST-PROCESSING (Optional but recommended) ---\n",
    "# Biomass cannot be negative, so clip predictions to 0 min\n",
    "ensemble_preds = np.maximum(ensemble_preds, 0)\n",
    "\n",
    "# Calculate Score\n",
    "val_mae = mean_absolute_error(y_val, ensemble_preds)\n",
    "print(f\"Ensemble Validation MAE: {val_mae:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "6413272f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-18T10:19:23.939875Z",
     "iopub.status.busy": "2025-11-18T10:19:23.938847Z",
     "iopub.status.idle": "2025-11-18T10:19:24.215029Z",
     "shell.execute_reply": "2025-11-18T10:19:24.213942Z"
    },
    "papermill": {
     "duration": 0.285067,
     "end_time": "2025-11-18T10:19:24.216626",
     "exception": false,
     "start_time": "2025-11-18T10:19:23.931559",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving models...\n",
      "Models saved successfully in the 'models' folder!\n"
     ]
    }
   ],
   "source": [
    "import joblib\n",
    "import os\n",
    "\n",
    "# Create a folder for models if it doesn't exist\n",
    "os.makedirs(\"models\", exist_ok=True)\n",
    "\n",
    "print(\"Saving models...\")\n",
    "\n",
    "# 1. Save the XGBoost Ensemble\n",
    "joblib.dump(model_xgb, \"models/xgboost_ensemble.pkl\")\n",
    "\n",
    "# 2. Save the LightGBM Ensemble\n",
    "joblib.dump(model_lgb, \"models/lightgbm_ensemble.pkl\")\n",
    "\n",
    "print(\"Models saved successfully in the 'models' folder!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0efe6bb",
   "metadata": {
    "papermill": {
     "duration": 0.006284,
     "end_time": "2025-11-18T10:19:24.229668",
     "exception": false,
     "start_time": "2025-11-18T10:19:24.223384",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45ee2e8b",
   "metadata": {
    "papermill": {
     "duration": 0.006218,
     "end_time": "2025-11-18T10:19:24.242209",
     "exception": false,
     "start_time": "2025-11-18T10:19:24.235991",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6e1596d",
   "metadata": {
    "papermill": {
     "duration": 0.006336,
     "end_time": "2025-11-18T10:19:24.254998",
     "exception": false,
     "start_time": "2025-11-18T10:19:24.248662",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "databundleVersionId": 14254895,
     "sourceId": 112509,
     "sourceType": "competition"
    },
    {
     "isSourceIdPinned": true,
     "modelId": 986,
     "modelInstanceId": 3325,
     "sourceId": 4533,
     "sourceType": "modelInstanceVersion"
    }
   ],
   "dockerImageVersionId": 31192,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 279.282772,
   "end_time": "2025-11-18T10:19:27.837954",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2025-11-18T10:14:48.555182",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
